{"componentChunkName":"component---src-templates-blog-post-js","path":"/LogisticRegression/","result":{"data":{"site":{"siteMetadata":{"title":"ljho01"}},"markdownRemark":{"id":"bd39c1b4-92fc-578d-b3e9-92f47200b86f","excerpt":"로지스틱 회귀는 이진 분류를 해결하는데 사용되는 모델이다. (k-class 모델, k-class & ordinal 모델 등의 변형모델을 통해 다항 로지스틱 회귀도 가능하다.) 이진 분류는 분류문제 아닌가? 왜 회귀라는 말을 썼을까? 계산과정에서 Numerical data…","html":"<p>로지스틱 회귀는 <strong>이진 분류</strong>를 해결하는데 사용되는 모델이다. (k-class 모델, k-class &#x26; ordinal 모델 등의 변형모델을 통해 다항 로지스틱 회귀도 가능하다.)</p>\n<p>이진 분류는 분류문제 아닌가? 왜 회귀라는 말을 썼을까?</p>\n<p>계산과정에서 Numerical data를 어쩌구.. 아무튼 회귀라고 부른다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/d75486b0-e3a6-4057-ad12-1dc4c70ea226/image.png\" alt=\"https://medium.com/@cmukesh8688/logistic-regression-sigmoid-function-and-threshold-b37b82a4cd79\"></p>\n<p>이진 분류라 데이터들이 0 혹은 1을 갖는다. 여기 파란 선은 sigmoid function으로, 선형회귀의 일차함수와 비슷한 역할을 한다. sigmoid function은 데이터의 실제 값이 1일 확률을 예측하여 보여준다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/544142c1-3dd6-4906-a15b-a99b0bda6ed6/image.png\" alt=\"https://www.researchgate.net/figure/A-Basic-sigmoid-function-with-two-parameters-c1-and-c2-as-commonly-used-for-subitizing_fig2_325868989\"></p>\n<p>여기서도 세타의 조정을 통해 데이터에 함수를 근사한다. 선형회귀하고 매우 비슷한데 이래서 로지스틱 회귀라고 하는가보다.</p>\n<p>로지스틱 회귀에서는 두 가지 정답을 제공할 수 있겠다. 확률과 확률에 기반한 판단이다.\r\n양성 카테고리에 속할 가능성 0.134, 0.655 (<code class=\"language-text\">scikit~~~.predict_proba(x_Data)</code>)\r\n또는\r\n0.6(cutoff)을 넘으니 양성, 못넘으니 음성 이렇게. (<code class=\"language-text\">scikit~~~.predict(x_Data)</code>)</p>\n<p>어떤 함수로 근사하는지 알았으면 모델을 학습시켜야한다.</p>\n<p>학습의 기준은 Cost function이 된다. 이 목적함수를 최대한 줄이는 파라미터를 찾는다.</p>\n<p>선형회귀에서는 일차함수가 들어갔기에 그의 제곱 모양인 MSE(평균제곱편차)도 이차함수 형태를 띄었다.\r\n분류문제의 경우 정답 오답을 구분해서 정확도를 구할 수도 있으나 이게 그렇게 좋은방법인 것 같지는 않다. 정확도가 같다면 또 다른 수단을 사용해야 된다.\r\n하지만 sigmoid 함수를 넣은 MSE는 모양이 기괴하다. 근데 자세한 이유는 아직 모름</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/4a299150-91e8-4b2a-9f91-738180068dad/image.png\" alt=\"\"></p>\n<p>보통의 MSE들은 극소이면 최소일 것이라 예상하는 면이 있고 얼추 맞아떨어지는 경우가 많은데 이 경우는 전혀 그렇지 않다. 그래서 MSE가 아닌 Cross-Entropy라고 하는 cost function을 사용한다. 이는 분류문제에서 자주 사용된다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/5623c5c9-ea49-40f3-9561-e19a05323a61/image.png\" alt=\"https://velog.io/@jakeseo_me/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-3-1-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5\"></p>\n<p>결과값에 로그를 씌우고 실제 정답을 곱해 합산한 것이다. 두 확률 분포의 차를 뜻한다.</p>\n<p><a href=\"https://hoya012.github.io/blog/cross_entropy_vs_kl_divergence/\">https://hoya012.github.io/blog/cross_entropy_vs_kl_divergence/</a></p>\n<p>이곳을 참고하면 더 자세히 배울 수 있다.\r\n<img src=\"https://velog.velcdn.com/images/ljho01/post/1c73dace-d51b-4c35-84c6-f49afe79a754/image.png\" alt=\"https://hoya012.github.io/blog/cross_entropy_vs_kl_divergence/\">\r\n엔트로피는 information의 평균이다. information은 로그(확률)이다.</p>\n<p>분류 문제들을 해결할 때 모델들은 단순하게 이게 class0이고 class1이고 딱 정해주지 않는다. 확률을 제공한다.\r\nclass0, class1, class2가 있을때는 <code class=\"language-text\">[0.31, 0.68, 0.01]</code> 이렇게 뱉는다.\r\n이는 categorical value들을 한 행으로 쭉 늘어놓는 one-hot encoding이다. 과정은 encoding, 결과는 one-hot label로 부른다.</p>\n<h4 id=\"softmax\" style=\"position:relative;\"><a href=\"#softmax\" aria-label=\"softmax permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>softmax</h4>\n<p>일련의 값들의 분포를 합이 1이 되도록 표준화하는 것</p>\n<h3 id=\"실습\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%8A%B5\" aria-label=\"실습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실습</h3>\n<p><code class=\"language-text\">from sklearn import linear_model</code>\r\n로지스틱 회귀도 선형모델 안에 있다.</p>\n<p>아래는 데이터 정제 과정에서 사용됨</p>\n<p><code class=\"language-text\">df[0].apply(function)</code>\r\n열.apply를 통해 데이터에 function을 일괄적용한 새로운 열을 리턴함</p>\n<p><code class=\"language-text\">nparray[:, a:b]</code>, <code class=\"language-text\">nparray[:, (2, 5, 9)]</code></p>\n<p>numpy array 슬라이싱.\r\n전자는 모든 행, a에서 b-1열까지 선택 / 후자는 모든 행, 2,5,9번 열만 선택\r\n둘다 이차원 array를 가정한다.</p>\n<p>다시 실습으로</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">x_train, x_test, y_train, y_test = model_selection.train_test_split(data_X, data_Y, test_size = 0.3, random_state = 0)</code></pre></div>\n<p>데이터를 학습용, 테스트용으로 쪼갠다. 테스트용 데이터는 30%로. random_state(random seed)를 지정함으로써 다음번 실행에도 똑같이 데이터가 섞이고 분배된다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">model = linear_model.LogisticRegression()\r\nmodel.fit(x_train, y_train)</code></pre></div>\n<p>목적함수인 CEE(Cross-Entropy Error)를 최소화하도록 학습한다. 학습이 완료되면 테스트한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import sklearn.metrics import accuracy_score\r\npred_test = model.predict(x_test)\r\nprint(accuracy_score(pred_test, y_test))</code></pre></div>\n<p>accuracy_score은 categorical data를 사용하는 분류문제에서만 사용된다.</p>\n<p>accuracy말고 다른 방식으로 결과를 분석해보자.</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/3a19703e-16f2-49d6-87d7-fb7d9719d866/image.png\" alt=\"\"></p>\n<p>한창 코로나 검사키트 나왔을때 위양성 위음성 어쩌구랑 같다.\r\n앞은 예측치의 정답여부에 따라 True/False를 붙여주고 뒤는 예측으로 붙여주면 안 헷갈린다.</p>\n<p>Accuracy는 (TP+TN)/(TP+TN+FP+FN)으로 구할 수 있다.</p>\n<p>Recall(재현율) = TP/(TP+FN) 실제 참인 것중 예측 성공한 것</p>\n<p>Precision(정밀도) = TP/(TP+FP) 참이라고 예측한 것들 중 실제로 맞은 것</p>\n<p>많이 헷갈린다.</p>\n<p>Recall은 참인 것에 대한 민감도를 의미한다. FP가 많더라도 FN을 줄여야 Recall을 끌어올릴 수 있다. 코로나같이 실제 양성을 구멍없이 잡아내야한다면 Recall이 중요하다.</p>\n<p>Precision은 예측 실패에 대한 민감도이다. 진양성을 좀 못잡더라도 위양성을 줄여야한다. 되도록 예측에 실패하면 안되는 스팸메일 거르기같은 경우 Precision이 중요하다.</p>\n<p>F1-Score는 Recall과 Precision의 조화평균이다. 둘다 고려할 경우 사용하면 된다.</p>\n<p>여기서 확장하면 F-Beta Score를 사용할 수 있는데 Recall과 Precision에 가중치를 부여하여 점수를 계산할 수 있다.</p>\n<p>ROC Curve &#x26; AUC</p>\n<p>진양성율: 실제 양성인것들 중 진양성인 것들의 비율 TP/(TP+FN)\r\n위양성율: 실제 음성인것들 중 위양성인 것들의 비율 FP/(TN+FP)</p>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/06c89a6d-bfe3-498d-9a72-7072fcae6c8b/image.png\" alt=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\"></p>\n<p>왼쪽 위로갈 수록 성능이 좋은것. 점선은 랜덤으로 찍었을 경우를 생각할 수 있다.</p>\n<p>수직 위로가면 양성을 빠짐없이 잡아내고\r\n수평 왼쪽으로 음성보고 양성이라고 하는 실수가 줄어든다(위양성)</p>\n<p>사진에서 확인할 수 있듯이 한쪽을 개선하면 한쪽이 나빠지는 경향이 있다. 저 선은 cutoff를 조절해가면서 그려진다고 보면 된다.</p>\n<p>선이 구불구불해서 성능비교가 힘들다면 적분해서 면적을 비교하면 된다. 이 면적이 AUC(Area Under the ROC Curve)이다.</p>\n<p>실용</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from sklearn.metrics import roc_curve, auc\r\npred_test = model.predict_proba(x_test)\r\nfpr, tpr, _ = roc_curve(y_true=y_test, y_score=pred_test[:,1])\r\nroc_auc = auc(fpr, tpr)</code></pre></div>\n<p><code class=\"language-text\">y_score=pred_test[:,1]</code> 이렇게 슬라이싱하는 이유는 <code class=\"language-text\">model.predict_proba</code>가 확률p와 1-p를 같이 제공하기 때문이다.\r\n<code class=\"language-text\">fpr</code>과 <code class=\"language-text\">tpr</code>은 ROC Curve상 특정 점(꺾이는점)들의 x,y좌표를 뜻한다.\r\n<code class=\"language-text\">_</code>는 굳이 필요없는 부분이다.</p>","tableOfContents":"<ul>\n<li>\n<ul>\n<li><a href=\"#softmax\">softmax</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%8A%B5\">실습</a></p>\n</li>\n</ul>","frontmatter":{"title":"AI/ML/Logistic Regression","date":"November 14, 2022","description":null,"category":"AI"}},"previous":{"fields":{"slug":"/Linear Regression/"},"frontmatter":{"title":"AI/ML/Linear Regression"}},"next":{"fields":{"slug":"/DecisionTree/"},"frontmatter":{"title":"AI/ML/Decision Tree"}},"allMarkdownRemark":{"totalCount":22,"group":[{"fieldValue":"AI","totalCount":14},{"fieldValue":"Algorithm","totalCount":3},{"fieldValue":"Data Structure","totalCount":1},{"fieldValue":"Gatsby","totalCount":1},{"fieldValue":"JavaScript","totalCount":2},{"fieldValue":"Python","totalCount":1}]}},"pageContext":{"id":"bd39c1b4-92fc-578d-b3e9-92f47200b86f","previousPostId":"7c12712a-f309-5729-b387-732938c71634","nextPostId":"db647d49-6a6b-5a71-9c3d-e8f1f1566db0"}},"staticQueryHashes":["2841359383"],"slicesMap":{}}