{"componentChunkName":"component---src-templates-blog-post-js","path":"/AI개요/","result":{"data":{"site":{"siteMetadata":{"title":"ljho01"}},"markdownRemark":{"id":"8be972e6-07a4-56e9-ad9e-e90b182e1a4f","excerpt":"https://dev.to/1801ayush/introduction-to-machine-learning-3mof 인공지능 (AI) 지각, 추론, 행동, 적응할 수 있는 프로그램 머신러닝 (Machine learning) 데이터가 늘어날수록 성능이 향상되는 알고리즘 정의 A field…","html":"<p><img src=\"https://velog.velcdn.com/images/ljho01/post/4377c570-70c0-4043-bdaa-13a2962e3088/image.png\" alt=\"https://dev.to/1801ayush/introduction-to-machine-learning-3mof\"></p>\n<h1 id=\"인공지능-ai\" style=\"position:relative;\"><a href=\"#%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-ai\" aria-label=\"인공지능 ai permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>인공지능 (AI)</h1>\n<p>지각, 추론, 행동, 적응할 수 있는 프로그램</p>\n<h1 id=\"머신러닝-machine-learning\" style=\"position:relative;\"><a href=\"#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-machine-learning\" aria-label=\"머신러닝 machine learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>머신러닝 (Machine learning)</h1>\n<p>데이터가 늘어날수록 성능이 향상되는 알고리즘</p>\n<h2 id=\"정의\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EC%9D%98\" aria-label=\"정의 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정의</h2>\n<blockquote>\n<p>A field of AI that gives computers the ability to learn from data, <strong>without being explicitly programmed</strong> - <em>Arthur Samuel, 1959</em></p>\n</blockquote>\n<blockquote>\n<p>A computer program is said to learn from experience E with repect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. - <em>Tom M. Mitchell, 1997</em></p>\n</blockquote>\n<p>프로그램이 데이터를 학습하고 성능이 향상된다는 점이 중요한 것 같다.</p>\n<h2 id=\"종류\" style=\"position:relative;\"><a href=\"#%EC%A2%85%EB%A5%98\" aria-label=\"종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>종류</h2>\n<p><img src=\"https://velog.velcdn.com/images/ljho01/post/c8d6841c-0805-4a27-a909-f3b2118a513f/image.png\" alt=\"\">\r\n지도학습(교사학습) / 비지도학습 / 강화학습</p>\n<h2 id=\"지도학습\" style=\"position:relative;\"><a href=\"#%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5\" aria-label=\"지도학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>지도학습</h2>\n<p>데이터와 함께 정답이 제공된다.\r\n데이터에 적합한 함수를 근사하는 과정이라고 볼 수 있다.</p>\n<ul>\n<li>\n<p>REGRESSSION(회귀)모델은 정답이 연속적인 값(Numerical)일 경우 (온도, 가격 등)</p>\n</li>\n<li>\n<p>CLASSIFICATION(분류)은 정답이 불연속적인, 범주형 값(Categorical)일 경우(강아지 품종 등)</p>\n</li>\n<li>\n<p>대표적인 알고리즘: Linear/Logistic regression, Decision Tree, Bayesian Classification, Neural Network, Hidden Markov Model (HMM) 등</p>\n</li>\n</ul>\n<h2 id=\"비지도학습\" style=\"position:relative;\"><a href=\"#%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5\" aria-label=\"비지도학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>비지도학습</h2>\n<p>정답이 제공되지 않고 데이터의 성향을 분석함.\r\nCLUSTERING(군집화)는 비슷한 것들 끼리 묶는것,\r\nDIMENSIONALLY REDUCTION(차원축소)은 데이터의 차원을 날리는 것이다. 차원은 2차원데이터에서 column같은 의미이다.\r\nex) 고객군 분류, 장바구니 분석(Association Rule), 추천 시스템 등</p>\n<h2 id=\"강화학습\" style=\"position:relative;\"><a href=\"#%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5\" aria-label=\"강화학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>강화학습</h2>\n<p>연속적인 단계마다 **상태(State)**를 인식하고 각 상태에 대해 결정한 **행동(Action)**들의 집합에 대해 환경으로부터 받는 **보상(Reward)**을 학습하여 전체 행동에 대한 보상을 최대화하는 **행동 선택 정책(Policy)**을 찾는 알고리즘.</p>\n<p>시행착오(Sequential decision making)를 통한 학습을 한다.\r\n알파고가 좋은 예다.</p>\n<p>알고리즘 - Monte Carlo Methods, Markov Decision Processes, Q-learning, Deep Q-learning, Dynamic Programming 등</p>\n<p>ex) 로봇 제어, 공정 최적화 등</p>\n<h2 id=\"학습이란\" style=\"position:relative;\"><a href=\"#%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9E%80\" aria-label=\"학습이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>학습이란?</h2>\n<p>예측과 정답 사이 오차를 줄여가는 과정</p>\n<h3 id=\"capaciity\" style=\"position:relative;\"><a href=\"#capaciity\" aria-label=\"capaciity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Capaciity</h3>\n<p>모델의 복잡성을 뜻함. 다항함수로 치면 차수를 생각할 수 있다. 인공신경망의 경우 layer의 개수를 들 수 있따.\r\n근사를 과하게 해서 Capacity가 올라가면 오버피팅이 발생할 수 있다. 그 반대는 언더피팅이 발생한다. (데이터의 경향성을 무시한 채 학습데이터에 대한 오차만 줄이는 방향으로 모델이 발전하면 오버피팅됨)</p>\n<h3 id=\"feature\" style=\"position:relative;\"><a href=\"#feature\" aria-label=\"feature permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>feature</h3>\n<p>데이터들에서 현상의 원인이 되는 독립변수, 결과가 되는 종속변수가 있는데 여기서 독립변수들을 feature라고 한다. 종속변수들은 회귀모델에서는 label, target 등으로 불리며 분류모델에서는 label 로 부른다</p>\n<h3 id=\"generalization\" style=\"position:relative;\"><a href=\"#generalization\" aria-label=\"generalization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>generalization</h3>\n<p>일반화. 학습데이터가 아닌 새 데이터가 투입되었을 때도 오차가 적게나오도록 하는 것이다.\r\ngeneralization error 라고 하면 새 데이터를 마주칠 시 오차를 말한다.</p>\n<h2 id=\"데이터-나누기교차-검증\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%82%98%EB%88%84%EA%B8%B0%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D\" aria-label=\"데이터 나누기교차 검증 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 나누기(교차 검증)</h2>\n<p>가지고 있는 데이터를 전부 모델의 학습용으로 써버리면, 테스트를 할 수 없게된다.\r\n그래서 세 가지 용도로 데이터를 나누어 사용한다.</p>\n<ul>\n<li>Training Data</li>\n<li>Validation Data</li>\n<li>Test Data</li>\n</ul>\n<p>Validation Data와 Test Data가 나한테는 비슷하게 느껴지는데(Validation Data를 사용하지 않는 경우도 있다고 한다.), 전자는 유효한 모델을 걸러낼 때 사용하고 후자는 걸러진 모델들의 성능을 평가할 때 사용하는 것 같다.</p>\n<p>세 가지 데이터간 비율은 데이터의 총량이 적을수록 6:2:2, 7:3 정도로 설정하고 엄청 많은 경우는 99:0.5:0.5 정도로 극단적으로 잡는다고 한다.</p>\n<h3 id=\"k-fold-cross-validation\" style=\"position:relative;\"><a href=\"#k-fold-cross-validation\" aria-label=\"k fold cross validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>K-Fold Cross Validation</h3>\n<p>Test Data를 제외한 나머지 데이터들로 여러 모델을 학습, 비교하는 방법이다. 데이터를 K등분내고 한 조각을 Validation Data로, 나머지 k-1조각을 Training Data로 활용하여 각 모델별 점수를 매기고 비교한다.\r\n<img src=\"https://velog.velcdn.com/images/ljho01/post/d83b7552-7b03-4cef-9251-f0be30abe03a/image.png\" alt=\"http://ethen8181.github.io/machine-learning/model_selection/model_selection.html\r\n\">\r\nk번 돌고 평균을 낸다.</p>\n<p>점수를 바탕으로 모델을 결정한 다음 등분을 내지 않은 전체 데이터를 대상으로 학습 후 따로 떼어뒀던 Test Data로 테스트 후 점수를 확인한다.</p>\n<h4 id=\"stratified\" style=\"position:relative;\"><a href=\"#stratified\" aria-label=\"stratified permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stratified</h4>\n<p>분류 문제에서 분류(class)가 몇개 없을 때 표본들에서 분포가 편향되는 것을 방지해주는 것이다. k = 10이면 10토막 모두 비슷한 분포를 맞춰준다는 것이다.</p>\n<p>데이터 불균형에 관한 글\r\n<a href=\"https://3months.tistory.com/414?category=756964\">https://3months.tistory.com/414?category=756964</a>\r\n<a href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data?hl=ko#oversample_the_minority_class\">https://www.tensorflow.org/tutorials/structured_data/imbalanced_data?hl=ko#oversample_the_minority_class</a></p>\n<h1 id=\"딥러닝-deep-learning\" style=\"position:relative;\"><a href=\"#%EB%94%A5%EB%9F%AC%EB%8B%9D-deep-learning\" aria-label=\"딥러닝 deep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>딥러닝 (Deep Learning)</h1>\n<p>머신러닝 중 신경망을 통해 데이터를 학습하는 알고리즘</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-ai\">인공지능 (AI)</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-machine-learning\">머신러닝 (Machine learning)</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%A0%95%EC%9D%98\">정의</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%A2%85%EB%A5%98\">종류</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5\">지도학습</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5\">비지도학습</a></p>\n</li>\n<li>\n<p><a href=\"#%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5\">강화학습</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9E%80\">학습이란?</a></p>\n<ul>\n<li><a href=\"#capaciity\">Capaciity</a></li>\n<li><a href=\"#feature\">feature</a></li>\n<li><a href=\"#generalization\">generalization</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%82%98%EB%88%84%EA%B8%B0%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D\">데이터 나누기(교차 검증)</a></p>\n<ul>\n<li>\n<p><a href=\"#k-fold-cross-validation\">K-Fold Cross Validation</a></p>\n<ul>\n<li><a href=\"#stratified\">Stratified</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%94%A5%EB%9F%AC%EB%8B%9D-deep-learning\">딥러닝 (Deep Learning)</a></p>\n</li>\n</ul>","frontmatter":{"title":"AI/개요","date":"October 31, 2022","description":null}},"previous":{"fields":{"slug":"/JS_prototype/"},"frontmatter":{"title":"JS/프로토타입 설명"}},"next":{"fields":{"slug":"/Linear Regression/"},"frontmatter":{"title":"AI/ML/Linear Regression"}}},"pageContext":{"id":"8be972e6-07a4-56e9-ad9e-e90b182e1a4f","previousPostId":"39bb5165-e8c8-5170-9749-cb6cb2bbc25d","nextPostId":"7c12712a-f309-5729-b387-732938c71634"}},"staticQueryHashes":["2841359383"],"slicesMap":{}}